\documentclass[10pt]{article}
\pdfoutput=1
%\usepackage{NotesTeX,lipsum}
\usepackage{NotesTeX,lipsum}
%\usepackage{showframe}

\title{\begin{center}{\Huge \textit{Notes}}\\{{\itshape Quantum Mechanics}}\end{center}}
\author{Yi Huang\footnote{\href{https://yiihuang.com/}{\textit{My Personal Website}}}}


\affiliation{
University of Minnesota
}

\emailAdd{yihphysics@gmail.com}

\begin{document}
	\maketitle
	\flushbottom
	\newpage
	\pagestyle{fancynotes}
	\part{Caprice}
	\section{Fall 2018}\label{sec:fall2018}
	\begin{margintable}\vspace{.8in}\footnotesize
		\begin{tabularx}{\marginparwidth}{|X}
		Section~\ref{sec:fall2018}. Fall 2018\\
		\end{tabularx}
	\end{margintable}

	This section is based on my Quantum mechanics course in Fall 2018. The textbook we use is Sakurai's \textit{Modern Quantum Mechanics}.

	\subsection{Derivation of (2.1.33)}


	Use iteration to prove it
	\begin{align*}
		i \hbar \frac{\partial}{\partial t} \mathcal{U}(t,t_0) &= H(t) \mathcal{U}(t,t_0) \\
		\mathcal{U}(t,t_0)
		&= \mathbb{I} + \int_{t_0}^{t} dt_1 \frac{H(t_1)}{i\hbar} \mathcal{U}(t_1,t_0) \\
		&= \mathbb{I} + \int_{t_0}^{t} dt_1 \frac{H(t_1)}{i\hbar} \left(\mathbb{I} +\int_{t_0}^{t_1} dt_2 \frac{H(t_2)}{i\hbar} \mathcal{U}(t_2,t_0)\right) \\
		&\vdots \\
		&= \mathbb{I} + \sum_{n=1}^{\infty}\left(\frac{1}{i \hbar}\right)^n \int_{t_0}^{t} dt_1 \int_{t_0}^{t_1} dt_2 \dots \int_{t_0}^{t_{n-1}} dt_{n} H(t_1)H(t_2) \dots H(t_n)
	\end{align*}

	\subsection{Postulate of quantum mechanics: inner product}

	The inner product postulate of quantum mechanics
	\begin{equation}
		\langle\alpha| \alpha \rangle \ge 0,
	\end{equation}
	comes from the probability interpretation of quantum mechanics.

	\subsection{Probability postulate}

	The probability postulate can not be proved right nor wrong. So how can we use probability theory to study the world?
	%我想问的问题是：“概率论的具体问题不符合概率论的公理或假设”这一点是没办法验证的（我们想要证伪嘛）。我们在没有进行这样一个验证的情况下，为什么就可以用概率论了，而且看起来应用的还不错。

	\subsection{(1.4.46) and (1.4.47)}

	Which is larger? (1.4.47) should be larger, because there's more terms in the summation.

	\subsection{Translation operator}

	Suppose a translation operator is given by
	\begin{equation}
		\hat{\mathscr{T}}(\dd \bfx') = 1-i\hat{\bfK}\cdot \dd\bfx',
	\end{equation}
	where $\hat{\bfK} = \hat{K}_j$, $j = 1,2,3$, is a vector with each component as Hermitian operator, $\dd \bfx' = \dd x'_i$, $i = 1,2,3$, is an infinitesimal displacement vector, which is just an array of numbers instead of operators.
	\begin{align*}
		[\hat{\bfx}, \hat{\mathscr{T}}(d\bfx')]_i &= -i (\hat{\bfx} \bfK\cdot \dd\bfx' - \bfK\cdot d\bfx'\hat{\bfx})_i \\
		&= -i(\hat{x}_i \hat{K}_j \dd x'_j - \hat{K}_j dx'_j \hat{x}_i) \\
		&= -i([\hat{x}_i, \hat{K}_j]) \dd x'_j,
	\end{align*}

	Also we know that
	\begin{align*}
		[\hat{\bfx}, \hat{\mathscr{T}}(d\bfx')]_i &= \dd x'_i \\
		&= \dd x'_j \delta_{ij},
	\end{align*}
	Thus we have the commutation relation between $\hat{x}_i$ and $\hat{K}_j$
	\begin{equation}
		[\hat{x}_i, \hat{K}_j] = i \delta_{ij}.
	\end{equation}

	\subsection{Complete set of compatible operators}

	If we are given a CSCO, we can choose a basis for the space of states made of common eigenvectors of the corresponding operators. We can uniquely identify each eigenvector by the set of eigenvalues it corresponds to.

	Why?

	\subsection{Typo a line above (1.4.57)}

	The value of $\lambda$ is actually
	\begin{equation}
		\lambda = - \frac{\langle \beta | \alpha \rangle}{\langle \beta | \beta \rangle}.
	\end{equation}

	\subsection{Galilean Invariance in Schrodinger equation}

	Consider a Galileo transformation:
	\begin{align*}
		x &= x' + v t', \\
		t &= t',
	\end{align*}
	then
	\begin{equation}
		f(x',t') \to f(x-vt,t),
	\end{equation}
	If we do the partial derivatives, then we will find
	\begin{align}
		\frac{\partial f}{\partial x'} &= \frac{\partial f }{\partial x}, \\
		\frac{\partial f}{\partial t'} &= \frac{\partial f }{\partial t } + v \frac{\partial f }{\partial t }, \label{Galileo_t_derivative}
	\end{align}
	The reason that $(\ref{Galileo_t_derivative})$ has a plus $v \partial_x f$ term is that when we do partial derivative $\partial_{t'}$, what we really want to do is to do time derivative only on the second argument in $f(x-vt,t)$, without touching the $t$ in the first argument. However, if we simply do $\partial_t f$ what we will get is actually $\partial_{t'} f - v \partial_x f$
	\begin{equation*}
		\partial_t f(x-vt,t) = \partial_{t'} f(x-vt, t') - v\partial_x f(x-vt,t),
	\end{equation*}
	or
	\begin{equation}
		\partial_{t'} f(x', t') = \partial_t f(x-vt,t) + v\partial_x f(x-vt,t).
	\end{equation}
	Thus we have
	\begin{align}
		\partial_{x'} &= \partial_x, \\
		\partial_{t'} &= \partial_t + v \partial_x.
	\end{align}

	\subsection{Residue Theorem and A Line Integral}

	We want to evaluate this integral
	\begin{equation}
		\int_0^{\infty} \frac{\ln x}{x^2 + a^2} dx,
	\end{equation}
	where $a>0$. To do it, we loop around the entire complex plane in the following way:

	see the picture.

	Therefore the contour integral can be written as
	\begin{align*}
		\int_0^{\infty} \frac{\ln x}{x^2 + a^2} dx &= \int_{\delta}^{R} \frac{\ln x}{x^2 + a^2} dx + \int_{C_R} \frac{\ln z}{z^2 + a^2} dz + \int^{\delta}_{R} \frac{\ln x + 2\pi i}{x^2 + a^2} dx + \int_{C_{\delta}} \frac{\ln z}{z^2 + a^2} dz \\
		&= 2\pi i \sum_{\mathbb{C}} \Res\left(\frac{\ln z}{z^2 + a^2}\right) \\
		&= 2\pi i \left(\frac{\ln a + i\pi/2}{2ia} + \frac{\ln a + i3\pi/2}{-2ia} \right) \\
		&= -i \frac{\pi^2}{a}.
	\end{align*}
	Since $\lim_{z\to0} z \ln z = 0$ and $\lim_{z \to \infty} \ln z/z = 0$, we eliminate two circle integrals
	\begin{align*}
		\int_{C_{\delta}} \frac{\ln z}{z^2 + a^2} dz &= 0,\\
		\int_{C_R} \frac{\ln z}{z^2 + a^2} dz &= 0,
	\end{align*}
	Therefore, after taking limit $R\to \infty$ and $\delta \to 0$, we obtain
	\begin{equation}
		\int_{0}^{\infty} \frac{\ln x}{x^2 + a^2} dx - \int_{0}^{\infty} \frac{\ln x + 2\pi i}{x^2 + a^2} dx = -i\frac{\pi^2}{a}.
	\end{equation}
	Although the integrals along both the banks of the branch cut are related to the integral we want to compute, but they cancel out each other and leave an integral which is not the one we want
	\begin{equation}
		\int_0^{\infty} \frac{1}{x^2 + a^2} = \frac{\pi}{2a}.
	\end{equation}

	On the other hand, this indicates us that if we want to compute $\int_0^{\infty} f(x) \ln x dx$, we should consider the complex integral $\oint_C f(z) \ln^2 z dz$, because in this case function $\ln^2 z$ on the two banks of branch cut partially cancel out, and leave the $\ln x$ term which is what we want.
	\begin{align*}
		\int_{0}^{\infty} \frac{\ln^2 x}{x^2 + a^2} dx - \int_{0}^{\infty} \frac{(\ln x + 2\pi i)^2}{x^2 + a^2} dx &= 2\pi i \sum_{\mathbb{C}} \Res\left(\frac{(\ln z)^2}{z^2 + a^2}\right) \\
		&= 2\pi i \left(\frac{(\ln a + i \pi/2)^2}{2ia} + \frac{(\ln a + i 3\pi/2)^2}{-2ia}\right) \\
		&= -i \frac{2\pi^2\ln a}{a} + \frac{2\pi^3}{a}.
	\end{align*}
	Thus
	\begin{equation}
		-4\pi i \int_{0}^{\infty} \frac{\ln x}{x^2 + a^2} dx + 4 \pi^2 \int_0^{\infty} \frac{1}{x^2 + a^2} dx = -i \frac{2\pi^2\ln a}{a} + \frac{2\pi^3}{a}.
	\end{equation}
	Therefore, we compute the integral
	\begin{equation}
		\int_{0}^{\infty} \frac{\ln x}{x^2 + a^2} dx = \frac{\pi}{2a}\ln a.
	\end{equation}

	\subsection{Order $\ln x$ and $-1/x$ at $x=0$}

	Consider the domain $x \in (0,1)$ , then we want to compare $\ln x$ and $-1/x$
	\begin{equation}
		r(x) = \frac{\ln x}{-1/x} = \frac{|\ln x|}{|1/x|} = -x\ln x,
	\end{equation}
	First we notice that $r(x) = -x \ln x > 0$ if $x \in (0,1)$.  Second, we do the derivative of this ratio and get
	\begin{equation}
		\frac{d r(x)}{dx} = -(\ln x +1),
	\end{equation}
	where $r'(x) > 0$ if $x < 1/e$, $r'(x) < 0$ if $x > 1/e$, $r'(x) = 0$ if $x = 1/e$, so $r(x)$ takes maximum at $x = 1/e$, and $r(1/e) = 1/e$,
	\begin{equation}
		0< r(x) < 1/e < 1.
	\end{equation}
	Therefore
	\begin{equation}
		|\ln x| < |- 1/x|, \quad x \in (0,1),
	\end{equation}
	or equivalently
	\begin{equation}
		\ln x > - 1/x, \quad x \in (0,1).
	\end{equation}

	\subsection{Saddle point approximation}

	Suppose we want to evaluate the following integral
	\begin{equation}
		I = \int_{-\infty}^{\infty} dx \e^{- f(x)}
	\end{equation}
	where
	\begin{equation}
		\lim_{x \to \pm \infty}f(x) = \infty
	\end{equation}
	Since the negative exponential function vanished very quickly when $f(x)$ becomes large, we only need to look at the contribution when $f(x)$ is at its minima. We can expand $f(x)$ around its minima $x_0$
	\begin{equation}
		f(x) = f(x_0) + \half f''(x_0)(x-x_0)^2 + \dots
	\end{equation}
	Then the integral can be written as
	\begin{align*}
		I &\approx \int_{-\infty}^{\infty} dx \exp[{- f(x_0) - \half f''(x_0)(x-x_0)^2})] \\
		&= \e^{-f(x_0)} \int_{-\infty}^{\infty} dx \exp[{- \half f''(x_0)(x-x_0)^2})] \\
		&= \e^{-f(x_0)} \sqrt{\frac{2\pi}{f''(x_0)}}
	\end{align*}
	If $f(x)$ has several local minima $\{x_i\}$, we should sum over all the contribution from the minima
	\begin{equation}
		I \approx \sum_i \e^{-f(x_i)} \sqrt{\frac{2\pi}{f''(x_i)}}
	\end{equation}

	\subsection{Qubit}
	All qubit states $\omega$ may be represented as $2 \times 2$ matrices
	\begin{gather}
		\rho = \frac{1}{2}
		\begin{pmatrix}
			1 + x_3 & x_1 - i x_2 \\
			x_1 + i x_2 & 1 - x_3
		\end{pmatrix} , \quad \underline{x} \in \mathbb{R}^3\\
		\rho \ge 0 , \quad \operatorname{tr}(\rho) = 1
	\end{gather}
	\begin{example}
		Show $\rho \ge 0 \Leftrightarrow |\underline{x}| \le 1$. Thus $\underline{x} = (x_1, x_2, x_3)$ is in ball of radius 1.
		\begin{equation}
			\rho = \frac{1}{2}(\mathbb{I} + x_1 \sigma_x + x_2 \sigma_y + x_3 \sigma_z)
		\end{equation}
	\end{example}
	\begin{proof}
		the eigenvalues of $\rho$ is $\frac{1}{2} (1 \pm |\underline{x}|)$. For $\rho \ge 0$, $\exists X \in \bbC^{2 \times 2}$, such that $\rho = X^H X$.
		Equivalently speaking, the eigenvalues of $\rho$ are all greater than or equal to 0. Therefore $|\underline{x}| \le 1$.
	\end{proof}
	For pure states of a qubit, the possible vector $\underline{x}$ is in a sphere of radius 1, which is called the Bloch sphere. But unfortunately the idea of Bloch sphere in 2D quantum system cannot be generalized to higher dimension.

	\subsection{The improved Bohr-Sommerfeld quantization formula}
	\begin{theorem}
		From the boundary condition (or connection condition) of WKB approximation at the classical turning points, we are able to write down the semiclassical quantization formula as follows
		\begin{equation}
			\oint p(x) \dd x = 2 \pi \hbar (n + \mu/4) \quad \text{with } \ \mu = N_{\text{soft}} + 2N_{\text{hard}}
		\end{equation}
		where $n = 0,1,2,\dots$, and $\mu$ is called \textit{Maslov index} and counts the number of classical turning points with smooth potential (soft wall) plus twice the number of classical turning points with Dirichlet boundary conditions (hard wall).
	\end{theorem}

	\subsection{Landau level for a charged particle in unifrom magnetic field}

	A charged paticle is moving in the presence of a uniform magnetic field in the $z$-direction ($\bfB = B \hat{z}$).
	Define the kinematical (or mechanical) momentum
	\begin{equation}
		\mathbf{\Pi} = m \ddt{\bfx} = \bfp - \frac{e \bfA}{c}
	\end{equation}
	We can compute the commutator between componets of kinematical momentum
	\begin{align*}
		[\Pi_i, \Pi_j] &= [p_i - e A_i(x) /c, p_j - e A_j(x) /c] \\
		&= [p_i, p_j] -\frac{e}{c} \{[A_i(x), p_j] + [p_i, A_j(x)]\} + \frac{e^2}{c^2}[A_i(x),A_j(x)] \\
		&= \frac{i \hbar e}{c}\left[ \del{A_j}{x_i} - \del{A_i}{x_i} \right] \\
		&= \frac{i \hbar e}{c} B_{ij} = \frac{i \hbar e}{c} \eps_{ijk} B_k \numberthis \label{eq: commutator of kinematical momentum}
	\end{align*}
	where $B_{ij} = \eps_{ijk} B_k$ is an antisymmetric tensor with matrix elements
	\begin{gather}
		B_{ij} = \pdv{A_j}{x_i} - \pdv{A_i}{x_i} \doteq
		\begin{pmatrix}
			0 & B_z & -B_y \\
			-B_z & 0 & B_x \\
			B_y & -B_x & 0
		\end{pmatrix} \\
		B_k = \eps_{ijk} \pdv{A_j}{x_i} = \thalf \eps_{ijk} B_{ij}
	\end{gather}
	We also note the commutators,
	\begin{equation}
		[x_i, p_j] = \frac{i \hbar}{m} \delta_{ij}
	\end{equation}
	The kinematical momentum commutators \eqref{eq: commutator of kinematical momentum} are proportional to the components of the magnetic field. Notice that this result holds regardless of the nature of the magnetic field (nonuniform, time-dependent, etc), with or without an electric field. If the magnetic field vanished, then the components of velocity commute with one another, as is obvious since in that case $\bfp = m \bfv$, and since $[p_i, p_j] = 0$.

	As assumed before, now we apply uniform magnetic field along $z$ axis, such that $\bfB = B \vu{z}$, the commutators \eqref{eq: commutator of kinematical momentum} become
	\begin{align*}
		[\Pi_x, \Pi_y] &= \frac{i \hbar e B}{c} \eps_{ijk} = i \hbar \sign(e) m \omega, \\
		[\Pi_x, \Pi_z] &= [\Pi_y, \Pi_z] = 0,
	\end{align*}
	where $\omega = \abs{e}B/mc$ is the frequency of the orbital gyration of the particle (the \textit{gyrogrequency}).
	Next we do a change of variable $X = \sign(e)\Pi_y/m\omega, P = \Pi_x$, with commutator $[X,P] = i\hbar$, such that we can rewrite the Hamiltonian as
	\begin{equation}
		H = \frac{\Pi^2}{2m} = \frac{P^2}{2m} + \thalf m \omega^2 X^2 + \frac{\Pi_z^2}{2m}
	\end{equation}
	The perpendicular kinetic energy appears as a harmonic oscillator, while the parallel kinetic energy appears as a one-dimensional free partice. Therefore, the energy spectrum of $H$ is immediately

	\begin{equation}
		E = (n+\thalf)\hbar \omega + \frac{\Pi_z^2}{2m}.
	\end{equation}

	\subsection{Order of even permutation group (alternating groyp)}

	The subset of the permutation group $S_n$ formed by even permutations is a group, called the alternating group $A_n$. We can check that it satisfies the definition of a group
	\begin{itemize}
		\item The identity is the do-nothing permutation $\sigma = ()$, and its determinant is 1 and $\sign (()) = 1$, that is $()$ is even.
		\item The composition of two even permutations is even, thus closure is satisfied.
		\item The inverse of an even permutation must be even. To show this, we know
		\begin{equation}
			P_{\sigma}^{\top} P_{\sigma} = I,
		\end{equation}
		so $\det(P_{\sigma}^{\top}) = \det(P_{\sigma})$ implies $\det(P_{\sigma}^{\top}) = 1$ if $\det(P_{\sigma}) = 1$.
	\end{itemize}
	The size of $A_n$ is $\thalf n!$, since for every even permutation, one can uniquely associate an odd one by exchanging the first two elements.
	\begin{proof}
			Say $A_n = {a_i}$, and $a_i$ is the element of alternating group. $E$ is the transposition that exchanges the first two elements, which means $E a_i$ is odd.
			Next we want to show that $E a_i \neq E a_j$ if $a_i \neq a_j$. Well, one can immediately prove this by saying that permutations are bijective, thus injective. Or we can do the following: Suppose $E a_i = E a_j$ for some $a_i \neq a_j$, then $E E a_i = E E a_j$, which implies $a_i = a_j$, because $E^2 = I$. Contradiction.
	\end{proof}

	\subsection{Cross product}

	Actually, there does not exist a cross product vector in space with more than 3 dimensions. The fact that the cross product of 3 dimensions vector gives an object which also has 3 dimensions is just pure coincidence. However, we can always define the cross product tensor in any dimension $n$, such that the cross product of $\bfa$ and $\bfb$ is defined as
	\begin{equation}
		c_{ij} = a_i b_j - a_j b_i. \label{def: cross product tensor}
	\end{equation}
	Therefore the cross product tensor is of rank 2 and it is antisymmetric. So the cross product tensor has $n(n-1)/2$ independent elements.

	The cross product in 3 dimensions is actually a tensor of rank 2 with 3 independent coordinates. We can create a 3-vector in 3 dimensions to represent these 3 independent elements.
	\begin{equation}
		c_{ij} =
		\begin{pmatrix}
			0 & c_3 & -c_2 \\
			-c_3 & 0 & c_1 \\
			c_2 & -c_1 & 0
		\end{pmatrix}
		= \eps_{ijk} c_k, \label{eq: cross product tensor}
	\end{equation}
	where $\bfc$ is the cross product vector of $\bfa$ and $\bfb$ in 3 dimensions and defined as
	\begin{equation}
		c_i = (\bfa \times \bfb)_i = \eps_{ijk} a_j b_k. \label{def: cross product vector}
	\end{equation}
	In addition to \eqref{eq: cross product tensor}, we can also express the cross product vector $\bfc$ interms of the cross product tensor $c_{ij}$
	\begin{equation}
		c_i = \thalf \eps_{ijk} c_{jk}
	\end{equation}
	Using the definition \eqref{def: cross product tensor} and \eqref{def: cross product vector}, we can immediately show this.
	\begin{align*}
		\thalf \eps_{ijk} c_{jk}
		&= \thalf \eps_{ijk} (a_j b_k - a_k b_j) \\
		&= \thalf \eps_{ijk} a_j b_k - \thalf \eps_{ijk} a_k b_j \\
		&= \eps_{ijk} a_j b_k = c_i.
	\end{align*}

	\subsection{Probability flux in the presence of electromagnetic field}

	We now study Schr\"{o}dinger's wave equation with $\phi$ and $\bfA$.
	\begin{align*}
		H \psi &= \frac{1}{2m}\qty[-i\hbar \grad - \frac{e \bfA(\bfx) }{c}] \vdot \qty[-i\hbar \grad - \frac{e \bfA(\bfx) }{c}] \psi(\bfx,t) + e \phi(\bfx) \psi(\bfx,t)\\
		&= -\frac{\hbar^2}{2m} \laplacian \psi + \frac{i \hbar e}{2mc} \div(\bfA \psi) + \frac{i \hbar e}{2mc} \bfA \vdot (\grad{\psi}) + \qty[\frac{e^2 A^2}{2mc^2} + e \phi] \psi \\
		&= -\frac{\hbar^2}{2m} \laplacian \psi + \frac{i \hbar e}{2mc} (\div{\bfA}) \psi + \frac{i \hbar e}{mc} \bfA \vdot (\grad{\psi}) + \qty[\frac{e^2 A^2}{2mc^2} + e \phi] \psi, \\
		(H \psi)^* &= -\frac{\hbar^2}{2m} \laplacian \psi^* - \frac{i \hbar e}{2mc} (\div{\bfA}) \psi^* - \frac{i \hbar e}{mc} \bfA \vdot (\grad{\psi^*}) + \qty[\frac{e^2 A^2}{2mc^2} + e \phi] \psi^*\\
	\end{align*}
	The probability density $\rho = \abs{\psi}^2$, we want to find the corresponding probability flux $\bfj$ such that the continuity equation is satisfied
	\begin{equation}
		\pdv{\rho}{t} + \div{\bfj} = 0.
	\end{equation}
	For this purpose we rewrite $\pdv{\rho}{t}$ using Sch\"{o}dinger's wave equation
	\begin{align*}
		\pdv{\rho}{t} &= \psi^* \pdv{\psi}{t} + \psi \pdv{\psi^*}{t} = \frac{1}{i \hbar} (\psi^* H \psi - \psi H \psi^*)\\
		&= \frac{i \hbar}{2m}(\psi^* \laplacian \psi + \psi \laplacian \psi^*) + \frac{e}{2mc}(\div{\bfA})(\psi^* \psi + \psi \psi^*) + \frac{e}{mc} \bfA \vdot (\psi^* \grad{\psi} + \psi \grad{\psi^*}) \\
		&= \frac{i \hbar}{2m} \div(\psi^* \grad{\psi} - \qcc) + \frac{e}{mc}\qty[(\div{\bfA}) \abs{\psi}^2 + \bfA \vdot \grad{\abs{\psi}^2}] \\
		&= - \div[\qty(\frac{\hbar}{m}) \Im{\psi^* \grad{\psi}} - \qty(\frac{e}{mc}) \bfA \abs{\psi}^2].
	\end{align*}
	Thus we have the probability flux
	\begin{align*}
		\bfj &= \qty(\frac{\hbar}{m}) \Im{\psi^* \grad{\psi}} - \qty(\frac{e}{mc}) \bfA \abs{\psi}^2 \\
		&= \qty(\frac{\hbar}{m}) \Im{\psi^* \qty[\grad - \qty(\frac{i e}{\hbar c}) \bfA] \psi},
	\end{align*}
	which is just what we expect from the substitution
	\begin{equation}
		\grad \to \grad - \qty(\frac{i e}{\hbar c}) \bfA.
	\end{equation}

	\subsection{Electromagnetic gauge transformations are canonical transformations}

	Consider a electromagnetic gauge transformation
	\begin{gather}
		\bfA' = \bfA + \grad \Lambda(\bfx, t), \\
		\phi' = \phi - \frac{1}{c} \pdv{t} \Lambda(\bfx, t)
	\end{gather}
	We claim that this gauge transformation is equivalent to a canonical transformation of type
	\begin{equation}
		L(q, \dot{q}, t)' = L(q, \dot{q}, t) + \dv{f(q,t)}{t},
	\end{equation}
	which generates new canonical variables
	\begin{gather}
		Q = q, \\
		P = \pdv{L'}{\dot{q}} = p + \pdv{f}{q}.
	\end{gather}
	To show this, we substitude the electromagnetic potential into the Lagrangian
	\begin{equation}
		L = \thalf m \dot{\bfx}^2 + \frac{e}{c} \dot{\bfx} \vdot \bfA - e \phi,
	\end{equation}
	which yields
	\begin{align*}
		L' &= \thalf m \dot{\bfx}^2 + \frac{e}{c} \dot{\bfx} \vdot (\bfA + \grad \Lambda) - e \qty(\phi - \frac{1}{c} \pdv{t} \Lambda) \\
		&= L + \frac{e}{c} \dv{\Lambda}{t}.
	\end{align*}

	\subsection{One-dimensional quantum ring}
	Consider a particle living in a circular ring with fixed radius $R$. Recall the gradient in cylindrical coordinates
	\begin{equation}
		\grad = \pdv{\rho} \vu*{\rho} + \frac{1}{\rho}\pdv{\phi} \vu*{\phi} + \pdv{z} \vu{z},
	\end{equation}
	and in our ring case, only the $\vu*{phi}$ component matters, so we obtain a reduced one-dimensional Schr\"{o}dinger's equation for a free particle
	\begin{equation}
		- \frac{\hbar^2}{2mR^2} \dv[2]{\phi} \psi(\phi) = E \psi(\phi). \label{eq: free particle in a ring}
	\end{equation}
	with periodic boundary condition
	\begin{equation}
		\psi(\phi + 2 \pi) = \psi(\phi).
	\end{equation}
	The general solution to \eqref{eq: free particle in a ring} is a plane wave $\e^{i n \phi}$, to satisfy the boundary condition we require $n \in \bbZ$. Therefore we have the eigenfunctions and energies labelled by the quantum number $n$
	\begin{align}
		\psi_n(\phi) &= \e^{i n \phi}, \\
		E_n &= \frac{\hbar^2 n^2}{2mR^2},
	\end{align}
	where $n \in \bbZ$.

	Now imagine that along the axis of the circle runs a solenoid of a radius $a < R$, carrying a steady electric current $I$. If the solenoid is long enough the magnetic field $\bfB = B \vu{z}$ is uniform inside and zero outside the solenoid. But the vector potential is not zero!
	\begin{equation}
		\bfA = \frac{\Psi}{2 \pi \rho} \vu*{\phi},
	\end{equation}
	where $Psi = \pi a^2 B$ is the magnetic flux through the solenoid. In the presence of this magnetic field, the kinematic momentum changes $\bfp \to \bfp - \frac{e}{c} \bfA$, or in terms of the gradient $\grad \to \grad - \tfrac{ie}{\hbar c} \bfA$, such that we have the Hamiltonian
	\begin{equation}
		H = \frac{\qty(\bfp - \frac{e}{c}\bfA)^2}{2m}.
	\end{equation}
	Since we only care about the $\vu*{\phi}$ component, the Hamiltonian can be written as
	\begin{equation}
		H = \frac{\hbar^2(\hat{l}_z-\alpha)^2}{2mR^2}
	\end{equation}
	where $\hat{l}_z = -i \dv{\phi}$ in $\phi$ representation, and $\alpha = ea^2B/2\hbar c$. The periodic boundary condition is still true even in the presence of magnetic field, because we still have the rotational symmetry, which means the eigenfunction $\psi(\phi) = \e^{i n \phi}$ with $n \in \bbZ$ is still true.
	\begin{gather}
		\psi_n(\phi) = \e^{i n \phi}, \\
		E_n = \frac{\hbar^2 (n- \alpha)^2}{2mR^2}.
	\end{gather}
	Alternatively one may choose a unitary gauge transformation $U(\hat{\phi})$ to solve the Schr\"{o}dinger's equation with magnetic field
	\begin{equation}
		U(\hat{\phi}) = \exp(-\frac{-i e}{\hbar c}\int^\phi \bfA \vdot \dd \bfl) = \e^{-i \alpha \hat{\phi}}
	\end{equation}
	which transforms the Hamiltonian to a field-free Hamiltonian in the following way
	\begin{equation}
		H' = U H H^{\dagger} = \e^{-i \alpha \hat{\phi}} \frac{\hbar^2(\hat{l}_z-\alpha)^2}{2mR^2} \e^{i \alpha \hat{\phi}} = \frac{\hbar^2 \hat{l}_z^2}{2mR^2},
	\end{equation}
	and we can think of $\e^{-i \alpha \hat{\phi}}$ as the translation operator for angular momentum $\hat{l}_z$, such that
	\begin{align}
		\e^{-i \alpha \hat{\phi}} \ \hat{l}_z \ \e^{i \alpha \hat{\phi}} &= \hat{l}_z + \alpha, \\
		\e^{-i \alpha \hat{\phi}} \ket{l_z} &= \ket{l_z + \alpha},
	\end{align}
	where $\ket{l_z}$ is the eigenket of $\hat{l}_z$.
	Given the original Schr\"{o}dinger equation $H \psi = E \psi$, we can rewrite it as
	\begin{gather}
		H' \psi' = U H U^{\dagger} U \psi = E \psi', \\
		- \frac{\hbar^2}{2m R^2} \dv[2]{\phi} \psi' = E \psi'
	\end{gather}
	The eigenenergies are conserved under gauge transformation. The general solution for $\psi'$ is $\e^{i k \phi}$, but $k \in \bbZ$ isn't necessary since the boundary conditions changes.
	If the periodic boundary conditions were true for the original wavefunction, such that
	\begin{equation}
		\psi(\phi + 2\pi) = \psi(\phi),
	\end{equation}
	then for the new wavefunction after gauge transformation, we have the ``twristed'' boundary conditions
	\begin{equation}
		\psi'(\phi + 2 \pi) = \e^{-i \alpha(\phi + 2 \pi)} \psi(\phi + 2\pi) = \e^{-i\alpha 2\pi} \psi'(\phi).
	\end{equation}
	Plug in the general solution for $\psi' = \e^{i k \phi}$,
	\begin{equation}
		\psi'(\phi + 2\pi) = \e^{i k (\phi + 2\pi)} = \e^{i k 2\pi} \psi'(\phi)
	\end{equation}
	we find the constraint of $k$
	\begin{equation}
		k = n - \alpha, \quad n \in \bbZ.
	\end{equation}
	Then $\psi'(\phi)$ and $\psi(\phi)$ are given by
	\begin{align}
		\psi'_n(\phi) &= \e^{i k \phi} = \e^{i(n-\alpha)\phi}, \\
		\psi_n(\phi) &= U^{\dagger} \psi'(\phi) = \e^{in \phi}.
	\end{align}
	Here we see that the original eigenfunction is indeed the same as the eigenfunction as the free particle. The eigenenergies are
	\begin{equation}
		E_n = \frac{\hbar^2 k^2}{2mR^2} = \frac{\hbar^2 (n-\alpha)^2}{2mR^2}.
	\end{equation}
	The kinetic angular momentum in presence of magnetic field is $\hbar k = \hbar(n - \alpha)$.

	\subsection{Quantum harmonic oscillator}

	The operator method can also be used to obtain the energy eigenfunctions in position space. Let us start with the ground state defined by
	\begin{equation}
		a \ket{0} = 0,
	\end{equation}
	which, in the $x$-representation, reads
	\begin{equation}
		\mel{x'}{a}{0} = \sqrt{\frac{m \omega}{2 \hbar}} \mel{x'}{x - \frac{i p}{m \omega}}{0} = 0.
	\end{equation}
	Recalling
	\begin{equation}
		\mel{x'}{p}{\alpha} = -i \hbar \dv{x'} \braket{x'}{\alpha},
	\end{equation}
	we can regard this as as differential equation for the ground state wave function $\braket{x'}{0}$
	\begin{equation}
		\qty(x' + x_0^2 \dv{x'}) \braket{x'}{0} = 0, \label{eq: ground state of harmonic oscillator}
	\end{equation}
	where we have introduced
	\begin{equation}
		x_0 = \sqrt{\frac{\hbar}{m \omega}},
	\end{equation}
	which sets the length scale of the oscillator. We see that the normalized solution to \eqref{eq: ground state of harmonic oscillator} is
	\begin{equation}
		\braket{x'}{0} = \frac{1}{\pi^{1/4}\sqrt{x_0}} \exp[-\half \qty(\frac{x'}{x_0})^2].
	\end{equation}
	The corresponding differential operators of $a$ and $a^{\dagger}$ are
	\begin{align}
		a &= \frac{1}{\sqrt{2} x_0} \qty(x' + x_0^2 \dv{x'}), \\
		a^{\dagger} &= \frac{1}{\sqrt{2} x_0} \qty(x' - x_0^2 \dv{x'}).
	\end{align}
	Thus We can also obtain the energy eigenfunctions for excited states
	\begin{align*}
		\braket{x'}{n} &= \mel{x'
		}{\frac{(a^{\dagger})^n}{\sqrt{n!}}}{0} \\
		&= \frac{1}{\pi^{1/4} \sqrt{2^n n!}  x_0^{n+1/2}} \qty(x' - x_0^2 \dv{x'})^n \exp[-\half \qty(\frac{x'}{x_0})^2]. \numberthis
	\end{align*}

	\subsection{Completeness of coherent states}
	Coherent states are overcomplete

	\subsection{Properties of Pauli matrices}

	The three Pauli matrices are defined as follows
	\begin{equation}
		\sigma_x = \mqty(\pmat{1}), \quad \sigma_y = \mqty(\pmat{2}), \quad \sigma_z = \mqty(\pmat{3}),
	\end{equation}
	and we can compute their commutators and anticommutators
	\begin{align}
		[\sigma_j, \sigma_k] &= 2i \eps_{jkl} \sigma_l, \\
		\{ \sigma_j, \sigma_k \} &= 2 \delta_{jk},
	\end{align}
	All three matrices multiplied by $i$ form a basis of $\mfs\mfu(2)$ Lie algebra.
	Also if we sum up the commutator and the anticommtator for $\sigma_{j,k}$ we have
	\begin{equation}
		\sigma_j \sigma_k = \delta_{jk} + i \eps_{jkl} \sigma_l.
	\end{equation}




\end{document}
